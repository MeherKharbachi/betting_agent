{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp simple_agent.scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler\n",
    "\n",
    ">  We define a custom scaler to preprocess RL observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import datetime\n",
    "from typing import Any, Dict\n",
    "import gym\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from d3rlpy.preprocessing.scalers import Scaler, register_scaler\n",
    "from betting_env.betting_env import Observation\n",
    "from betting_agent.datastructure.team_features import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, our RL observations hold certain particular numerical information such as `Opta gameId`, `Opta home team Id`, `Opta away team Id`, the 22 `Opta players Id`, and betting odds (`1X2` and `Asian Handicap`). through this custom scaler, we aim to fetch our `MongoDb` database and extract various features pertaining to both competing teams and the 22 players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SimpleScaler(Scaler):\n",
    "    TYPE = \"simple\"\n",
    "    OBS = 18\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit_with_env(\n",
    "        self,\n",
    "        env: gym.Env,  # Gym environment.\n",
    "    ):\n",
    "        \"Gets scaling parameters from environment.\"\n",
    "        pass\n",
    "\n",
    "    def transform(\n",
    "        self,\n",
    "        x: Observation,  # Observation.\n",
    "    ) -> np.ndarray:  # Observation features, shape=(1, new_shape), new_shape is the number of features extracted from the database.\n",
    "        \"Returns processed observation.\"\n",
    "        \n",
    "        \n",
    "        if isinstance(x, Observation):\n",
    "\n",
    "            # Real-Analytics Home Team Id.\n",
    "            ra_home_team_id = x.ra_teams_ids[0]\n",
    "\n",
    "            # Real-Analytics Away Team Id.\n",
    "            ra_away_team_id = x.ra_teams_ids[1]\n",
    "\n",
    "            # Game Date.\n",
    "            game_date = x.game_date\n",
    "\n",
    "            # 1X2 and Asian Handicap odds.\n",
    "            if x.numerical_observation.shape[0] != 1:\n",
    "                x.numerical_observation = (\n",
    "                    x.numerical_observation.reshape(1, -1)\n",
    "                )\n",
    "            odds = x.numerical_observation[0][25:]\n",
    "\n",
    "            # AH Line.\n",
    "            ah_line = x.ah_line\n",
    "\n",
    "            # Extract Home and Away team features\n",
    "            home_team_feats = self.get_team_features(\n",
    "                team_id=ra_home_team_id, date=game_date\n",
    "            )\n",
    "            away_team_feats = self.get_team_features(\n",
    "                team_id=ra_away_team_id, date=game_date\n",
    "            )\n",
    "            \n",
    "            # Concatenate all features (Home and Away teams features + 1X2 and AH odds).\n",
    "            x = np.hstack(\n",
    "                (home_team_feats, away_team_feats, odds, ah_line)\n",
    "            ).reshape(1, -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reverse_transform(\n",
    "        self,\n",
    "        x: torch.Tensor,  # Processed observation.\n",
    "    ) -> torch.Tensor:\n",
    "        \"Returns reversely transformed observations.\"\n",
    "        pass\n",
    "\n",
    "    def get_params(\n",
    "        self,\n",
    "        deep: bool = False,  # Flag to deeply copy objects.\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"Returns scaling parameters.\"\n",
    "        return {}\n",
    "\n",
    "    def get_team_features(\n",
    "        self,\n",
    "        team_id: str,  # Real-analytics team identifier.\n",
    "        date: datetime.datetime,  # Game Date\n",
    "    ) -> np.array:  # Team features.\n",
    "        \"Extract teams features from Database.\"\n",
    "        feats = TeamFeatures.get_latest(ra_team_id=team_id, date=date)\n",
    "        team_feats = np.array(\n",
    "            [feats.elo]  # Elo .\n",
    "            + [feats.glicko]  # Glicko.\n",
    "            + [feats.quality_overall]  # team Overall rating.\n",
    "            + [feats.quality_attack]  # Attack rating.\n",
    "            + [feats.quality_midfield]  # Midfield rating.\n",
    "            + [feats.quality_defence]  # Defence rating.\n",
    "        )\n",
    "\n",
    "        return team_feats\n",
    "    \n",
    "register_scaler(SimpleScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
