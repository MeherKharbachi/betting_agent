{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Agent.agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D3rlpy Agent\n",
    "\n",
    ">  Simulate a trading strategy using a custom football betting environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import pandas as pd\n",
    "import d3rlpy\n",
    "import torch\n",
    "from betting_agent.Utils.uncache import *\n",
    "from betting_agent.Utils.monkey_patching import *\n",
    "from d3rlpy.preprocessing.scalers import Scaler\n",
    "from betting_agent.config.localconfig import CONFIG, DB_HOSTS\n",
    "from betting_env.betting_env import BettingEnv\n",
    "from betting_env.utils.data_extractor import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>game_optaId</th>\n",
       "      <th>gameDate</th>\n",
       "      <th>homeTeamId</th>\n",
       "      <th>homeTeam_optaId</th>\n",
       "      <th>awayTeamId</th>\n",
       "      <th>awayTeam_optaId</th>\n",
       "      <th>tgt_gd</th>\n",
       "      <th>tgt_outcome</th>\n",
       "      <th>preGameOdds1</th>\n",
       "      <th>...</th>\n",
       "      <th>homeTeamLineupIds</th>\n",
       "      <th>homeTeamLineupSlots</th>\n",
       "      <th>homeTeamFormation</th>\n",
       "      <th>home_team_lineup_received_at</th>\n",
       "      <th>awayTeamName</th>\n",
       "      <th>awayTeamLineup</th>\n",
       "      <th>awayTeamLineupIds</th>\n",
       "      <th>awayTeamLineupSlots</th>\n",
       "      <th>awayTeamFormation</th>\n",
       "      <th>away_team_lineup_received_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0cc49c3230e300b529b270951b3b70b3224481add8354...</td>\n",
       "      <td>991007</td>\n",
       "      <td>2018-08-21 18:45:00</td>\n",
       "      <td>9ca1f9a87934693b07890de4b4528b0f3ae4065a67ec38...</td>\n",
       "      <td>80</td>\n",
       "      <td>38ca605bcd29a5a37697ca66e533ae817ced71b6bf275c...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>...</td>\n",
       "      <td>[40346, 28654, 49539, 169432, 214225, 116215, ...</td>\n",
       "      <td>[1, 3, 2, 9, 6, 11, 7, 5, 4, 8, 10]</td>\n",
       "      <td>4-2-3-1</td>\n",
       "      <td>2018-08-21 18:15:00</td>\n",
       "      <td>Leeds United</td>\n",
       "      <td>{\"Kalvin Phillips\": \"DMC\", \"Jamie Shackleton\":...</td>\n",
       "      <td>[155405, 221610, 98760, 57913, 220037, 38588, ...</td>\n",
       "      <td>[4, 2, 9, 3, 1, 5, 7, 8, 10, 11, 6]</td>\n",
       "      <td>4-1-4-1</td>\n",
       "      <td>2018-08-21 18:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0c48eee0b1a42e0d84cb0a947fe2c64f9e1aa7015922f...</td>\n",
       "      <td>990998</td>\n",
       "      <td>2018-08-21 18:45:00</td>\n",
       "      <td>bc9d5de208258f2f95282c59e9551310be9d319ebc6e4e...</td>\n",
       "      <td>24</td>\n",
       "      <td>4a625f945d8f58984be0aa7b2ac6409a23ed9cf48e4260...</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>...</td>\n",
       "      <td>[106423, 12744, 184341, 57714, 103920, 17601, ...</td>\n",
       "      <td>[4, 9, 8, 3, 10, 1, 2, 5, 6, 11, 7]</td>\n",
       "      <td>4-3-3</td>\n",
       "      <td>2018-08-21 18:15:00</td>\n",
       "      <td>Ipswich Town</td>\n",
       "      <td>{\"Jonas Knudsen\": \"DL\", \"Janoi Donacien\": \"DR\"...</td>\n",
       "      <td>[82187, 154936, 101881, 115557, 28530, 19910, ...</td>\n",
       "      <td>[3, 2, 10, 7, 1, 8, 9, 11, 4, 5, 6]</td>\n",
       "      <td>4-1-4-1</td>\n",
       "      <td>2018-08-21 18:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58b1242154c8055252582229abfc4680460278834c4433...</td>\n",
       "      <td>991001</td>\n",
       "      <td>2018-08-21 18:45:00</td>\n",
       "      <td>58301066042bbdf19de8fe7d41afc53626b5aa79034712...</td>\n",
       "      <td>72</td>\n",
       "      <td>bbb63e4ea54b0d60b48a1f8440254d7e656dfbfcbef825...</td>\n",
       "      <td>88</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.09</td>\n",
       "      <td>...</td>\n",
       "      <td>[80246, 19152, 193576, 155529, 124120, 41753, ...</td>\n",
       "      <td>[7, 6, 2, 1, 4, 3, 11, 8, 5, 9, 10]</td>\n",
       "      <td>4-5-1</td>\n",
       "      <td>2018-08-21 18:15:00</td>\n",
       "      <td>Hull City</td>\n",
       "      <td>{\"Evandro Goebel\": \"AMC\", \"Jordy De Wijs\": \"DC...</td>\n",
       "      <td>[52287, 173549, 120449, 28541, 107692, 178186,...</td>\n",
       "      <td>[10, 6, 2, 9, 11, 7, 4, 5, 3, 1, 8]</td>\n",
       "      <td>4-4-1-1</td>\n",
       "      <td>2018-08-21 18:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3a604f5616b39eb17fc8d1eed07d5248e387bf400294b2...</td>\n",
       "      <td>991000</td>\n",
       "      <td>2018-08-21 18:45:00</td>\n",
       "      <td>e2bfbb5453a7853e049b9434db74d4d06b8c5560ff7cf9...</td>\n",
       "      <td>52</td>\n",
       "      <td>d6fe4a4ffbf1e1a0ae9d4bbed16e94042d9bf01e57eb55...</td>\n",
       "      <td>113</td>\n",
       "      <td>-3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.44</td>\n",
       "      <td>...</td>\n",
       "      <td>[91068, 89184, 49083, 106606, 42996, 95767, 23...</td>\n",
       "      <td>[10, 1, 8, 7, 2, 4, 11, 3, 6, 5, 9]</td>\n",
       "      <td>4-3-3</td>\n",
       "      <td>2018-08-21 18:15:00</td>\n",
       "      <td>Bristol City</td>\n",
       "      <td>{\"Josh Brownhill\": \"DMR\", \"Jack Hunt\": \"DR\", \"...</td>\n",
       "      <td>[172782, 73716, 55563, 110735, 106257, 235530,...</td>\n",
       "      <td>[4, 2, 7, 6, 10, 3, 8, 5, 11, 1, 9]</td>\n",
       "      <td>4-4-2</td>\n",
       "      <td>2018-08-21 18:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              gameId  game_optaId  \\\n",
       "0  d0cc49c3230e300b529b270951b3b70b3224481add8354...       991007   \n",
       "1  c0c48eee0b1a42e0d84cb0a947fe2c64f9e1aa7015922f...       990998   \n",
       "2  58b1242154c8055252582229abfc4680460278834c4433...       991001   \n",
       "3  3a604f5616b39eb17fc8d1eed07d5248e387bf400294b2...       991000   \n",
       "\n",
       "             gameDate                                         homeTeamId  \\\n",
       "0 2018-08-21 18:45:00  9ca1f9a87934693b07890de4b4528b0f3ae4065a67ec38...   \n",
       "1 2018-08-21 18:45:00  bc9d5de208258f2f95282c59e9551310be9d319ebc6e4e...   \n",
       "2 2018-08-21 18:45:00  58301066042bbdf19de8fe7d41afc53626b5aa79034712...   \n",
       "3 2018-08-21 18:45:00  e2bfbb5453a7853e049b9434db74d4d06b8c5560ff7cf9...   \n",
       "\n",
       "   homeTeam_optaId                                         awayTeamId  \\\n",
       "0               80  38ca605bcd29a5a37697ca66e533ae817ced71b6bf275c...   \n",
       "1               24  4a625f945d8f58984be0aa7b2ac6409a23ed9cf48e4260...   \n",
       "2               72  bbb63e4ea54b0d60b48a1f8440254d7e656dfbfcbef825...   \n",
       "3               52  d6fe4a4ffbf1e1a0ae9d4bbed16e94042d9bf01e57eb55...   \n",
       "\n",
       "   awayTeam_optaId  tgt_gd  tgt_outcome  preGameOdds1  ...  \\\n",
       "0                2       0          1.0          3.13  ...   \n",
       "1               40       2          0.0          2.05  ...   \n",
       "2               88      -1          2.0          3.09  ...   \n",
       "3              113      -3          2.0          2.44  ...   \n",
       "\n",
       "                                   homeTeamLineupIds  \\\n",
       "0  [40346, 28654, 49539, 169432, 214225, 116215, ...   \n",
       "1  [106423, 12744, 184341, 57714, 103920, 17601, ...   \n",
       "2  [80246, 19152, 193576, 155529, 124120, 41753, ...   \n",
       "3  [91068, 89184, 49083, 106606, 42996, 95767, 23...   \n",
       "\n",
       "                   homeTeamLineupSlots  homeTeamFormation  \\\n",
       "0  [1, 3, 2, 9, 6, 11, 7, 5, 4, 8, 10]            4-2-3-1   \n",
       "1  [4, 9, 8, 3, 10, 1, 2, 5, 6, 11, 7]              4-3-3   \n",
       "2  [7, 6, 2, 1, 4, 3, 11, 8, 5, 9, 10]              4-5-1   \n",
       "3  [10, 1, 8, 7, 2, 4, 11, 3, 6, 5, 9]              4-3-3   \n",
       "\n",
       "   home_team_lineup_received_at  awayTeamName  \\\n",
       "0           2018-08-21 18:15:00  Leeds United   \n",
       "1           2018-08-21 18:15:00  Ipswich Town   \n",
       "2           2018-08-21 18:15:00     Hull City   \n",
       "3           2018-08-21 18:15:00  Bristol City   \n",
       "\n",
       "                                      awayTeamLineup  \\\n",
       "0  {\"Kalvin Phillips\": \"DMC\", \"Jamie Shackleton\":...   \n",
       "1  {\"Jonas Knudsen\": \"DL\", \"Janoi Donacien\": \"DR\"...   \n",
       "2  {\"Evandro Goebel\": \"AMC\", \"Jordy De Wijs\": \"DC...   \n",
       "3  {\"Josh Brownhill\": \"DMR\", \"Jack Hunt\": \"DR\", \"...   \n",
       "\n",
       "                                   awayTeamLineupIds  \\\n",
       "0  [155405, 221610, 98760, 57913, 220037, 38588, ...   \n",
       "1  [82187, 154936, 101881, 115557, 28530, 19910, ...   \n",
       "2  [52287, 173549, 120449, 28541, 107692, 178186,...   \n",
       "3  [172782, 73716, 55563, 110735, 106257, 235530,...   \n",
       "\n",
       "                   awayTeamLineupSlots awayTeamFormation  \\\n",
       "0  [4, 2, 9, 3, 1, 5, 7, 8, 10, 11, 6]           4-1-4-1   \n",
       "1  [3, 2, 10, 7, 1, 8, 9, 11, 4, 5, 6]           4-1-4-1   \n",
       "2  [10, 6, 2, 9, 11, 7, 4, 5, 3, 1, 8]           4-4-1-1   \n",
       "3  [4, 2, 7, 6, 10, 3, 8, 5, 11, 1, 9]             4-4-2   \n",
       "\n",
       "  away_team_lineup_received_at  \n",
       "0          2018-08-21 18:15:00  \n",
       "1          2018-08-21 18:15:00  \n",
       "2          2018-08-21 18:15:00  \n",
       "3          2018-08-21 18:15:00  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixtures = data_aggregator(\n",
    "    db_hosts=DB_HOSTS, config=CONFIG, db_host=\"prod_atlas\", limit=4\n",
    ")\n",
    "fixtures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Monkey-patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from d3rlpy import torch_utility\n",
    "from d3rlpy.online.buffers import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "torch_utility.torch_api = torch_api\n",
    "ReplayBuffer.append = append\n",
    "ReplayBuffer._add_last_step = add_last_step\n",
    "uncache([\"d3rlpy.torch_utility\",\"d3rlpy.online.buffers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D3rlpy Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from betting_agent.Utils.scaler import CustomScaler\n",
    "from betting_agent.Utils.network_architecture import *\n",
    "from d3rlpy.algos import DQN\n",
    "from d3rlpy.online.explorers import LinearDecayEpsilonGreedy\n",
    "from d3rlpy.models.optimizers import OptimizerFactory\n",
    "from d3rlpy.preprocessing.scalers import register_scaler\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose a function that will prepare the `Reinforcement learning` algorithm prior to training. Initially, we initialise the `Betting environment` with the supplied data, then we set up the `Scaler`, which will transform our observations to particular features from the Database, and last, we set up the `Buffer`; `D3rlpy` supports both offline and online training tools. In this case, the `Buffer` will try several experiences in order to obtain a useful dataset.\n",
    "\n",
    "Furthemore, we supply additionally an `Optimizer` to update weights and reduce losses for the `Neural Network` and an `Explorer` which will apply the `exploration-exploitation` dilemma which must exist side by side because The majority of the time, the `epsilon-greedy` strategy takes the action with the largest estimated reward. `Exploration` allows us to experiment with new ideas, which are frequently at contradiction with what we have already learned. The procedure starts with 100% `exploration` and subsequently decreases to 10%.\n",
    "\n",
    "We should note that the `D3rlpy` package has several `RL` algorithms; in our situation, we will choose the `DQN` algorithm (Deep Q-Network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def rl_algo_preparation(\n",
    "    fixtures: pd.DataFrame,  # All provided games.\n",
    "    algo: d3rlpy.algos = DQN,  # D3rlpy RL algorithm.\n",
    "    algo_batch_size=32,  #  Mini-batch size.\n",
    "    algo_learning_rate=2.5e-4,  # Algo learning rate.\n",
    "    algo_target_update_interval=100,  # Interval to update the target network.\n",
    "    algo_scaler: Scaler = CustomScaler,  # The scaler for data transformation.\n",
    "    optimizer: torch.optim = Adam,  # Algo Optimizer.\n",
    "    optimizer_weight_decay=1e-4,  # Optimizer weight decay.\n",
    "    maxlen_buffer=1000000,  #  The maximum number of data length.\n",
    "    explorer_start_epsilon=1.0,  # The beginning epsilon.\n",
    "    explorer_end_epsilon=0.1,  # The end epsilon.\n",
    "    explorer_duration=100000,  # The scheduling duration.\n",
    "):\n",
    "    \"Prepare RL algorithm components.\"\n",
    "    # Init betting env.\n",
    "    env = BettingEnv(fixtures)\n",
    "\n",
    "    # Init Scaler.\n",
    "    register_scaler(algo_scaler)\n",
    "    custom_scaler = algo_scaler()\n",
    "\n",
    "    # Init Buffer.\n",
    "    buffer = ReplayBuffer(env=env, maxlen=maxlen_buffer)\n",
    "\n",
    "    # Init the epsilon-greedy explorer\n",
    "    explorer = LinearDecayEpsilonGreedy(\n",
    "        start_epsilon=explorer_start_epsilon,\n",
    "        end_epsilon=explorer_end_epsilon,\n",
    "        duration=explorer_duration,\n",
    "    )\n",
    "\n",
    "    # Init Optimizer.\n",
    "    optim_factory = OptimizerFactory(optimizer, weight_decay=optimizer_weight_decay)\n",
    "\n",
    "    # Init RL Algo.\n",
    "    rl_algo = algo(\n",
    "        batch_size=algo_batch_size,\n",
    "        learning_rate=algo_learning_rate,\n",
    "        target_update_interval=algo_target_update_interval,\n",
    "        optim_factory=optim_factory,\n",
    "        scaler=custom_scaler,\n",
    "        encoder_factory=CustomEncoderFactory(feature_size=env.action_space.n),\n",
    "    )\n",
    "\n",
    "    return env, buffer, explorer, rl_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from d3rlpy.algos.base import AlgoBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "AlgoBase.fit_online = fit_online\n",
    "uncache([\"d3rlpy.torch_utility\", \"d3rlpy.online.buffers\", \"d3rlpy.algos.base\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def launch_training(\n",
    "    fixtures: pd.DataFrame,  # All provided games.\n",
    "    training_steps: int = 100,  # The number of total steps to train.\n",
    "    n_steps_per_epoch: int = 50,  # The number of steps per epoch.\n",
    "    update_start_step: int = 50,  #  The steps before starting updates.\n",
    "    algo: d3rlpy.algos = DQN,  # D3rlpy RL algorithm.\n",
    "    algo_batch_size: int = 32,  #  Mini-batch size.\n",
    "    algo_learning_rate: float = 2.5e-4,  # Algo learning rate.\n",
    "    algo_target_update_interval: int = 100,  # Interval to update the target network.\n",
    "    algo_scaler: Scaler = CustomScaler,  # The scaler for data transformation.\n",
    "    optimizer: torch.optim = Adam,  # Algo Optimizer.\n",
    "    optimizer_weight_decay: float = 1e-4,  # Optimizer weight decay.\n",
    "    maxlen_buffer: int = 1000000,  #  The maximum number of data length.\n",
    "    explorer_start_epsilon: float = 1.0,  # The beginning epsilon.\n",
    "    explorer_end_epsilon: float = 0.1,  # The end epsilon.\n",
    "    explorer_duration: int = 100,  # The scheduling duration.\n",
    "    eval_epsilon: float = 0.3,  # Greedy-epsilon for evaluation.\n",
    "    show_progress: bool = True,  # Flag to show progress bar for iterations.\n",
    "    save_metrics: bool = True,  # Flag to record metrics. If False, the log directory is not created and the model parameters are not saved.\n",
    "):\n",
    "    \"Launch RL algorithm training.\"\n",
    "    # Get algo params.\n",
    "    env, buffer, explorer, rl_algo = rl_algo_preparation(\n",
    "        fixtures=fixtures,\n",
    "        algo=algo,\n",
    "        algo_batch_size=algo_batch_size,\n",
    "        algo_learning_rate=algo_learning_rate,\n",
    "        algo_target_update_interval=algo_target_update_interval,\n",
    "        algo_scaler=algo_scaler,\n",
    "        optimizer=optimizer,\n",
    "        optimizer_weight_decay=optimizer_weight_decay,\n",
    "        maxlen_buffer=maxlen_buffer,\n",
    "        explorer_start_epsilon=explorer_start_epsilon,\n",
    "        explorer_end_epsilon=explorer_end_epsilon,\n",
    "        explorer_duration=explorer_duration,\n",
    "    )\n",
    "    # Launch training.\n",
    "    eval_env = BettingEnv(fixtures)\n",
    "    rl_algo.fit_online(\n",
    "        env,  # Gym environment.\n",
    "        buffer,  # Buffer.\n",
    "        explorer,  # Explorer.\n",
    "        n_steps=training_steps,  # Train for 'training_steps' steps.\n",
    "        n_steps_per_epoch=n_steps_per_epoch,  # Evaluation is performed every 'n_steps_per_epoch' steps.\n",
    "        update_start_step=update_start_step,  # Parameter update starts after 'update_start_step' steps.\n",
    "        save_metrics=save_metrics,  # Save metrics.\n",
    "        show_progress=show_progress,  # Show progress.\n",
    "        eval_env=eval_env,  # Environment for evaluation.\n",
    "        eval_epsilon=eval_epsilon,  # Greedy-epsilon for evaluation.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-07 13:50.32 [info     ] Directory is created at d3rlpy_logs/DQN_online_20230307135032\n",
      "2023-03-07 13:50.32 [debug    ] Fitting scaler...              scler=none\n",
      "2023-03-07 13:50.32 [debug    ] Building model...\n",
      "2023-03-07 13:50.32 [debug    ] Model has been built.\n",
      "2023-03-07 13:50.32 [info     ] Parameters are saved to d3rlpy_logs/DQN_online_20230307135032/params.json params={'action_scaler': None, 'batch_size': 32, 'encoder_factory': {'type': 'custom', 'params': {'feature_size': 16}}, 'gamma': 0.99, 'generated_maxlen': 100000, 'learning_rate': 0.00025, 'n_critics': 1, 'n_frames': 1, 'n_steps': 1, 'optim_factory': {'optim_cls': 'Adam', 'weight_decay': 0.0001}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'real_ratio': 1.0, 'reward_scaler': None, 'scaler': {'type': 'none', 'params': {}}, 'target_update_interval': 100, 'use_gpu': None, 'algorithm': 'DQN', 'observation_shape': (30,), 'action_size': 16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6376585a96ed47c3912113a82f18df93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-07 13:50.52 [info     ] Model parameters are saved to d3rlpy_logs/DQN_online_20230307135032/model_20.pt\n",
      "2023-03-07 13:50.52 [info     ] DQN_online_20230307135032: epoch=1 step=20 epoch=1 metrics={'time_inference': 0.3187492609024048, 'time_environment_step': 0.0008553028106689453, 'time_step': 0.6009551525115967, 'rollout_return': -86.75, 'evaluation': -2.29500000000001} step=20\n",
      "2023-03-07 13:51.13 [info     ] Model parameters are saved to d3rlpy_logs/DQN_online_20230307135032/model_40.pt\n",
      "2023-03-07 13:51.13 [info     ] DQN_online_20230307135032: epoch=2 step=40 epoch=2 metrics={'time_inference': 0.3378914475440979, 'time_environment_step': 0.0008766531944274902, 'time_step': 0.6662898898124695, 'rollout_return': -11.75, 'time_sample_batch': 0.00020953587123325894, 'time_algorithm_update': 0.003481898988996233, 'loss': 125.31766183035714, 'evaluation': 2.2699999999999934} step=40\n",
      "2023-03-07 13:51.34 [info     ] Model parameters are saved to d3rlpy_logs/DQN_online_20230307135032/model_60.pt\n",
      "2023-03-07 13:51.34 [info     ] DQN_online_20230307135032: epoch=3 step=60 epoch=3 metrics={'time_inference': 0.31021939516067504, 'time_environment_step': 0.0005808353424072265, 'time_sample_batch': 0.00014449357986450194, 'time_algorithm_update': 0.0027396082878112793, 'loss': 109.10697784423829, 'time_step': 0.6342749714851379, 'rollout_return': -28.140000000000004, 'evaluation': 27.680000000000007} step=60\n",
      "2023-03-07 13:51.55 [info     ] Model parameters are saved to d3rlpy_logs/DQN_online_20230307135032/model_80.pt\n",
      "2023-03-07 13:51.55 [info     ] DQN_online_20230307135032: epoch=4 step=80 epoch=4 metrics={'time_inference': 0.2728728771209717, 'time_environment_step': 0.0007506251335144043, 'time_sample_batch': 0.00018720626831054689, 'time_algorithm_update': 0.002959239482879639, 'loss': 97.13594551086426, 'time_step': 0.5437061667442322, 'rollout_return': 9.940000000000007, 'evaluation': 38.44000000000001} step=80\n",
      "2023-03-07 13:52.18 [info     ] Model parameters are saved to d3rlpy_logs/DQN_online_20230307135032/model_100.pt\n",
      "2023-03-07 13:52.18 [info     ] DQN_online_20230307135032: epoch=5 step=100 epoch=5 metrics={'time_inference': 0.32876871824264525, 'time_environment_step': 0.0009024381637573242, 'time_sample_batch': 0.0002153635025024414, 'time_algorithm_update': 0.0032249569892883303, 'loss': 82.62300682067871, 'time_step': 0.6789684891700745, 'rollout_return': 83.24000000000001, 'evaluation': 73.80000000000003} step=100\n"
     ]
    }
   ],
   "source": [
    "launch_training(\n",
    "    fixtures=fixtures,\n",
    "    algo=DQN,\n",
    "    algo_scaler=CustomScaler,\n",
    "    optimizer=Adam,\n",
    "    explorer_duration=100,\n",
    "    training_steps=100,\n",
    "    n_steps_per_epoch=20,  \n",
    "    update_start_step=20,\n",
    "    save_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
